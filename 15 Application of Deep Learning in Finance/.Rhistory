y <- c(0,0,1,0) 				          # target value
# hidden layer bias and weights
W1 <- matrix(c(0.1,-0.2,0.1,0.4,0.2,0.9),nrow=2,byrow=T)
# output layer bias and weights
W2 <- matrix(c(0.2,-0.5,0.1),nrow=1)
X1 <- cbind(1, X)
h <- logistic(W1 %*% t(X1))       # logistic hidden h'
h <- rbind(1, h)
o <- W2 %*% h                     # linear output o'
(err <- y - o)                    # output error
(mean_sse <- mean(err^2))         # mean SSE
################################################################################
lr <- 0.5                         # learning rate: $\eta$
n <- length(y)
del2 <- -2*err                    # output layer $\delta_2$
Delta_W2 <- -lr*del2 %*% t(h)     # $\Delta W2 = -\eta \delta_2 (h')^T$
new_W2 <- W2 + Delta_W2 / n       # new output weights: $W2 = W2 + \Delta W2$
del1 <- (t(W2) %*% del2)*h*(1-h)  # hidden layer $\delta_1$
del1 <- del1[-1,]                 # remove from cbind(1, X)
Delta_W1 <- -lr*del1 %*% X1       # $\Delta W1 = -\eta \delta_1 x^T$
new_W1 <- W1 + Delta_W1 / n       # new hidden weights: $W1 = W1 + \Delta W1$
new_h <- logistic(new_W1 %*% t(X1))
new_h <- rbind(1, new_h)
new_o <- new_W2 %*% new_h
new_err <- y - new_o
(new_mean_sse <- mean(new_err^2)) # new mean SSE
h
X1
W1
logistic(W1 %*% t(X1))
h
logistic <- function(x) 1/(1+exp(-x))
X <- matrix(c(0.4,0.7,0.8,0.9,1.3,1.8,-1.3,-0.9),ncol=2,byrow=T)
y <- c(0,0,1,0) 				          # target value
# hidden layer bias and weights
W1 <- matrix(c(0.1,-0.2,0.1,0.4,0.2,0.9),nrow=2,byrow=T)
# output layer bias and weights
W2 <- matrix(c(0.2,-0.5,0.1),nrow=1)
X1 <- cbind(1, X)
h <- logistic(W1 %*% t(X1))       # logistic hidden h'
h <- rbind(1, h)
o <- W2 %*% h                     # linear output o'
(err <- y - o)                    # output error
(mean_sse <- mean(err^2))         # mean SSE
################################################################################
lr <- 0.5                         # learning rate: $\eta$
n <- length(y)
del2 <- -2*err                    # output layer $\delta_2$
Delta_W2 <- -lr*del2 %*% t(h)     # $\Delta W2 = -\eta \delta_2 (h')^T$
new_W2 <- W2 + Delta_W2 / n       # new output weights: $W2 = W2 + \Delta W2$
del1 <- (t(W2) %*% del2)*h*(1-h)  # hidden layer $\delta_1$
del1 <- del1[-1,]                 # remove from cbind(1, X)
Delta_W1 <- -lr*del1 %*% X1       # $\Delta W1 = -\eta \delta_1 x^T$
new_W1 <- W1 + Delta_W1 / n       # new hidden weights: $W1 = W1 + \Delta W1$
new_h <- logistic(new_W1 %*% t(X1))
new_h <- rbind(1, new_h)
new_o <- new_W2 %*% new_h
new_err <- y - new_o
(new_mean_sse <- mean(new_err^2)) # new mean SSE
lr <- 0.5                         # learning rate: $\eta$
n <- length(y)
del2 <- -2*err                    # output layer $\delta_2$
Delta_W2 <- -lr*del2 %*% t(h)     # $\Delta W2 = -\eta \delta_2 (h')^T$
new_W2 <- W2 + Delta_W2 / n       # new output weights: $W2 = W2 + \Delta W2$
del1 <- (t(W2) %*% del2)*h*(1-h)  # hidden layer $\delta_1$
del1
del1[-1,]
d <- read.csv("../Datasets/fin-ratio.csv")
X <- subset(d, select=-c(HSI)); y <- d$HSI
y <- as.factor(d$HSI)       # y as factor
set.seed(4002)
fin.nn <- ANNet(X,y,size=3,maxit=200,try=10)
fin.nn$value                # best value
summary(fin.nn)
pred <- fin.nn$fit > 0.5    # check if it belongs to group 1
table(pred, y)              # classification table
d <- read.csv("../Datasets/fin-ratio.csv")
names(d)
X <- subset(d, select=-c(HSI)); y <- d$HSI
set.seed(4012)
fin.nn <- nnet(X,y,size=2,linout=T,maxit=200)
# set max. number of iterations to 200
pred <- round(fin.nn$fit)   # round the fitted values
table(pred, y)              # classification table
d <- read.csv("../Datasets/fin-ratio.csv")
names(d)
X <- subset(d, select=-c(HSI)); y <- d$HSI
set.seed(4012)
fin.nn <- nnet(X,y,size=2,linout=T)
# set max. number of iterations to 200
pred <- round(fin.nn$fit)   # round the fitted values
table(pred, y)              # classification table
d <- read.csv("../Datasets/fin-ratio.csv")
names(d)
X <- subset(d, select=-c(HSI)); y <- d$HSI
set.seed(4012)
fin.nn <- nnet(x=d[,-ncol(df)],y=d$HSI,size=2,linout=T)
d <- read.csv("../Datasets/fin-ratio.csv")
names(d)
X <- subset(d, select=-c(HSI)); y <- d$HSI
set.seed(4012)
fin.nn <- nnet(x=d[,-ncol(d)],y=d$HSI,size=2,linout=T)
# set max. number of iterations to 200
pred <- round(fin.nn$fit)   # round the fitted values
table(pred, y)              # classification table
df <- read.csv("../Datasets/fin-ratio.csv")
fin.nn <- nnet(x=df[,-ncol(df)], y=df$HSI, size=2, linout=TRUE)
summary(fin.nn)
pred <- round(fin.nn$fit)
table(df$HSI, pred)
df <- read.csv("../Datasets/fin-ratio.csv")
fin.nn <- nnet(x=df[,-ncol(df)], y=df$HSI, size=3, linout=TRUE)
summary(fin.nn)
pred <- round(fin.nn$fit)
table(df$HSI, pred)
library(nnet)
library(devtools)
source_url('https://gist.githubusercontent.com/Peque/41a9e20d6687f2f3108d/raw/85e14f3a292e126f1454864427e3a189c2fe33f3/nnet_plot_update.r')
set.seed(4012)
df <- iris
classes <- factor(df$Species)
levels(classes) <- 1:length(levels(classes))
df$Species <- classes
df <- apply(df, 2, as.numeric)
# One hidden layer with 2 neurons and linear output unit; ncol(df)=5
iris.nn <- nnet(x=df[,-ncol(df)], y=df[,ncol(df)], size=2, linout=TRUE)
summary(iris.nn)
plot.nnet(iris.nn, wts.only = F)
df[c(1, 51, 101),]
sum((df[,ncol(df)] - iris.nn$fitted.values)^2)    # MSE
pred <- round(iris.nn$fit)	# round the fitted values
table(df[,ncol(df)], pred)		# classification table
################################################################################
df <- read.csv("../Datasets/fin-ratio.csv")
fin.nn <- nnet(x=df[,-ncol(df)], y=df$HSI, size=2, linout=TRUE)
summary(fin.nn)
pred <- round(fin.nn$fit)
table(df$HSI, pred)
iris.nn
set.seed(4012)
rnorm(13)
df <- read.csv("../Datasets/fin-ratio.csv")
fin.nn <- nnet(x=df[,-ncol(df)], y=df$HSI, size=2, linout=TRUE)
summary(fin.nn)
pred <- round(fin.nn$fit)
table(df$HSI, pred)
set.seed(4012)
rnorm(17)
df <- read.csv("../Datasets/fin-ratio.csv")
fin.nn <- nnet(x=df[,-ncol(df)], y=df$HSI, size=2, linout=TRUE)
summary(fin.nn)
pred <- round(fin.nn$fit)
table(df$HSI, pred)
set.seed(4012)
iris.nn <- nnet(x=df[,-ncol(df)], y=df[,ncol(df)], size=2, linout=TRUE)
df <- read.csv("../Datasets/fin-ratio.csv")
fin.nn <- nnet(x=df[,-ncol(df)], y=df$HSI, size=2, linout=TRUE)
summary(fin.nn)
pred <- round(fin.nn$fit)
table(df$HSI, pred)
source_url('https://gist.githubusercontent.com/Peque/41a9e20d6687f2f3108d/raw/85e14f3a292e126f1454864427e3a189c2fe33f3/nnet_plot_update.r')
set.seed(4012)
df <- iris
classes <- factor(df$Species)
levels(classes) <- 1:length(levels(classes))
df$Species <- classes
df <- apply(df, 2, as.numeric)
# One hidden layer with 2 neurons and linear output unit; ncol(df)=5
iris.nn <- nnet(x=df[,-ncol(df)], y=df[,ncol(df)], size=2, linout=TRUE)
summary(iris.nn)
plot.nnet(iris.nn, wts.only = F)
df[c(1, 51, 101),]
sum((df[,ncol(df)] - iris.nn$fitted.values)^2)    # MSE
pred <- round(iris.nn$fit)	# round the fitted values
table(df[,ncol(df)], pred)		# classification table
################################################################################
set.seed(4012)
iris.nn <- nnet(x=df[,-ncol(df)], y=df[,ncol(df)], size=2, linout=TRUE)
df <- read.csv("../Datasets/fin-ratio.csv")
fin.nn <- nnet(x=df[,-ncol(df)], y=df$HSI, size=2, linout=TRUE)
summary(fin.nn)
pred <- round(fin.nn$fit)
table(df$HSI, pred)
set.seed(4012)
rnorm(1)
rnorm(1)
set.seed(4012)
rnorm(2)
set.seed(4012)
rnorm(3)
df <- read.csv("../Datasets/fin-ratio.csv")
fin.nn <- nnet(x=df[,-ncol(df)], y=df$HSI, size=2, linout=TRUE)
summary(fin.nn)
pred <- round(fin.nn$fit)
table(df$HSI, pred)
set.seed(4012)
rnorm(2)
df <- read.csv("../Datasets/fin-ratio.csv")
fin.nn <- nnet(x=df[,-ncol(df)], y=df$HSI, size=2, linout=TRUE)
summary(fin.nn)
pred <- round(fin.nn$fit)
table(df$HSI, pred)
set.seed(4012)
rnorm(1)
df <- read.csv("../Datasets/fin-ratio.csv")
fin.nn <- nnet(x=df[,-ncol(df)], y=df$HSI, size=2, linout=TRUE)
summary(fin.nn)
pred <- round(fin.nn$fit)
table(df$HSI, pred)
df <- read.csv("../Datasets/fin-ratio.csv")
set.seed(4012)
for (i in 1:100){
rnorm(i)
fin.nn <- nnet(x=df[,-ncol(df)], y=df$HSI, size=2, linout=TRUE)
summary(fin.nn)
pred <- round(fin.nn$fit)
if (sum(pred) == 0) print(i)
}
?nnet
set.seed(4012)
for (i in 1:100){
rnorm(i)
fin.nn <- nnet(x=df[,-ncol(df)], y=df$HSI, size=2, linout=TRUE, trace=F)
pred <- round(fin.nn$fit)
if (sum(pred) == 0) print(i)
}
set.seed(4012)
rnorm(83)
df <- read.csv("../Datasets/fin-ratio.csv")
fin.nn <- nnet(x=df[,-ncol(df)], y=df$HSI, size=2, linout=TRUE)
summary(fin.nn)
pred <- round(fin.nn$fit)
table(df$HSI, pred)
for (i in 1:100){
set.seed(4012)
rnorm(i)
fin.nn <- nnet(x=df[,-ncol(df)], y=df$HSI, size=2, linout=TRUE, trace=F)
pred <- round(fin.nn$fit)
if (sum(pred) == 0) print(i)
}
set.seed(4012)
rnorm(19)
df <- read.csv("../Datasets/fin-ratio.csv")
fin.nn <- nnet(x=df[,-ncol(df)], y=df$HSI, size=2, linout=TRUE)
summary(fin.nn)
pred <- round(fin.nn$fit)
table(df$HSI, pred)
set.seed(4002)
# logV starts from 0; y starts from 1
y <- array(0, 1000)
ln_v <- array(0, 1001)
for (i in 2:1001){
ln_v[i] <- 0.5 - 0.332 * ln_v[i-1] + 0.12 * rnorm(1, 0, 1)
y[i-1] <- sqrt(exp(ln_v[i])) * rnorm(1, 0, 1)
}
library(invgamma)
seed=4002; num_it=1e5
#MCMC_SV <- function(y, num_it=1e5, seed=4002){
MH_V <- function(logV_, y_t, phi, psi, lamb){
logV_old <- logV_[1]; logV_t <- logV_[2]; logV_new <- logV_[3]
mu_t <- (phi*(1-psi) + psi*(logV_new + logV_old)) / (1 + psi^2)
tilde_mu_t <- mu_t + lamb/2 * (y_t^2 * exp(-mu_t) - 1)
tilde_lambda <- lamb / (1 + psi^2)
logV_prop <- rnorm(1, tilde_mu_t, tilde_lambda)
nominator <- exp(-y_t^2/2 * exp(-logV_prop))
denominator <- exp(-y_t^2/2 * exp(-mu_t) * (1 + mu_t - logV_prop))
target_diff <- nominator / denominator
if (!is.na(target_diff)){
if (runif(1) < min(1, target_diff)){
return (logV_prop)
}
}
return (logV_t)
return (MH_V(logV_, y_t, phi, psi, lamb))
}
# prior: phi ~ N(0, 1); psi ~ N(0, 1); sigma ~ IG(2.5, 0.025)
mu_phi <- 0; sig2_phi <- 1; mu_psi <- 0; sig2_psi <- 1; alpha_lamb <- 2.5; beta_lamb <- 0.025
T <- length(y)
set.seed(seed)
phi <- rnorm(1, mean=mu_phi, sd=sqrt(sig2_phi))
psi <- rnorm(1, mean=mu_psi, sd=sqrt(sig2_psi))
lamb <- rinvgamma(1, shape=alpha_lamb, rate=beta_lamb)
#phi <- 0.6 ; psi <- -0.4; lamb <- 0.2
logV_hist <- matrix(0, nrow=num_it, ncol=T+1)
phi_hist <- array(phi, dim=num_it)
psi_hist <- array(psi, dim=num_it)
lamb_hist <- array(lamb, dim=num_it)
for (t in 2:T+1){
logV_hist[1,t] <- phi + psi * logV_hist[1,t-1] + sqrt(lamb) * rnorm(1, 0, 1)
}
for (i in 2:num_it){
# MH sampling for ln V
logV <- c(logV_hist[i-1,], 0)
for (t in 1:T){
# logV starts from 0; y starts from 1
# a little bug for t = 0 and t = T + 1, but run it first
logV[t+1] <- MH_V(logV[c(t, t+1, t+2)], y[t], phi, psi, lamb)
}
logV <- logV[-(T+2)]
# Gibbs sampling for parameters
mu_phi <- (sig2_phi*sum(logV[-1]-psi*logV[-(T+1)]) + lamb*mu_phi)/(T*sig2_phi + lamb)
sig2_phi <- lamb*sig2_phi/(T*sig2_phi + lamb)
phi <- rnorm(1, mean=mu_phi, sd=sqrt(sig2_phi))
mu_psi <- (sig2_psi*sum(logV[-(T+1)]*(logV[-1]-phi)) + lamb*mu_psi) / (sig2_psi*sum(logV[-(T+1)]^2) + lamb)
sig2_psi <- lamb*sig2_psi/(sig2_psi*sum(logV[-(T+1)]^2) + lamb)
psi <- rnorm(1, mean=mu_psi, sd=sqrt(sig2_psi))
#alpha_lamb <- alpha_lamb + T/2
beta_lamb <- 1/2*sum((logV[-1] - phi - psi*logV[-(T+1)])^2) + beta_lamb
lamb <- rinvgamma(1, shape=alpha_lamb, rate=beta_lamb)
print(paste(phi, psi, lamb, i))
logV_hist[i,] <- logV
phi_hist[i] <- phi
psi_hist[i] <- psi
lamb_hist[i] <- lamb
}
library(invgamma)
seed=4002; num_it=1e5
#MCMC_SV <- function(y, num_it=1e5, seed=4002){
MH_V <- function(logV_, y_t, phi, psi, lamb){
logV_old <- logV_[1]; logV_t <- logV_[2]; logV_new <- logV_[3]
mu_t <- (phi*(1-psi) + psi*(logV_new + logV_old)) / (1 + psi^2)
tilde_mu_t <- mu_t + lamb/2 * (y_t^2 * exp(-mu_t) - 1)
tilde_lambda <- lamb / (1 + psi^2)
logV_prop <- rnorm(1, tilde_mu_t, sqrt(tilde_lambda))
nominator <- exp(-y_t^2/2 * exp(-logV_prop))
denominator <- exp(-y_t^2/2 * exp(-mu_t) * (1 + mu_t - logV_prop))
target_diff <- nominator / denominator
if (!is.na(target_diff)){
if (runif(1) < min(1, target_diff)){
return (logV_prop)
}
}
return (logV_t)
return (MH_V(logV_, y_t, phi, psi, lamb))
}
# prior: phi ~ N(0, 1); psi ~ N(0, 1); sigma ~ IG(2.5, 0.025)
mu_phi <- 0; sig2_phi <- 1; mu_psi <- 0; sig2_psi <- 1; alpha_lamb <- 2.5; beta_lamb <- 0.025
T <- length(y)
set.seed(seed)
phi <- rnorm(1, mean=mu_phi, sd=sqrt(sig2_phi))
psi <- rnorm(1, mean=mu_psi, sd=sqrt(sig2_psi))
lamb <- rinvgamma(1, shape=alpha_lamb, rate=beta_lamb)
#phi <- 0.6 ; psi <- -0.4; lamb <- 0.2
logV_hist <- matrix(0, nrow=num_it, ncol=T+1)
phi_hist <- array(phi, dim=num_it)
psi_hist <- array(psi, dim=num_it)
lamb_hist <- array(lamb, dim=num_it)
for (t in 2:T+1){
logV_hist[1,t] <- phi + psi * logV_hist[1,t-1] + sqrt(lamb) * rnorm(1, 0, 1)
}
for (i in 2:num_it){
# MH sampling for ln V
logV <- c(logV_hist[i-1,], 0)
for (t in 1:T){
# logV starts from 0; y starts from 1
# a little bug for t = 0 and t = T + 1, but run it first
logV[t+1] <- MH_V(logV[c(t, t+1, t+2)], y[t], phi, psi, lamb)
}
logV <- logV[-(T+2)]
# Gibbs sampling for parameters
mu_phi <- (sig2_phi*sum(logV[-1]-psi*logV[-(T+1)]) + lamb*mu_phi)/(T*sig2_phi + lamb)
sig2_phi <- lamb*sig2_phi/(T*sig2_phi + lamb)
phi <- rnorm(1, mean=mu_phi, sd=sqrt(sig2_phi))
mu_psi <- (sig2_psi*sum(logV[-(T+1)]*(logV[-1]-phi)) + lamb*mu_psi) / (sig2_psi*sum(logV[-(T+1)]^2) + lamb)
sig2_psi <- lamb*sig2_psi/(sig2_psi*sum(logV[-(T+1)]^2) + lamb)
psi <- rnorm(1, mean=mu_psi, sd=sqrt(sig2_psi))
#alpha_lamb <- alpha_lamb + T/2
beta_lamb <- 1/2*sum((logV[-1] - phi - psi*logV[-(T+1)])^2) + beta_lamb
lamb <- rinvgamma(1, shape=alpha_lamb, rate=beta_lamb)
print(paste(phi, psi, lamb, i))
logV_hist[i,] <- logV
phi_hist[i] <- phi
psi_hist[i] <- psi
lamb_hist[i] <- lamb
}
set.seed(4002)
# logV starts from 0; y starts from 1
y <- array(0, 1000)
ln_v <- array(0, 1001)
for (i in 2:1001){
ln_v[i] <- 0.5 - 0.332 * ln_v[i-1] + 0.12 * rnorm(1, 0, 1)
y[i-1] <- sqrt(exp(ln_v[i])) * rnorm(1, 0, 1)
}
library(invgamma)
seed=4002; num_it=1e5
#MCMC_SV <- function(y, num_it=1e5, seed=4002){
MH_V <- function(logV_, y_t, phi, psi, lamb){
logV_old <- logV_[1]; logV_t <- logV_[2]; logV_new <- logV_[3]
mu_t <- (phi*(1-psi) + psi*(logV_new + logV_old)) / (1 + psi^2)
tilde_mu_t <- mu_t + lamb/2 * (y_t^2 * exp(-mu_t) - 1)
tilde_lambda <- lamb / (1 + psi^2)
logV_prop <- rnorm(1, tilde_mu_t, sqrt(tilde_lambda))
nominator <- exp(-y_t^2/2 * exp(-logV_prop))
denominator <- exp(-y_t^2/2 * exp(-mu_t) * (1 + mu_t - logV_prop))
target_diff <- nominator / denominator
if (!is.na(target_diff)){
if (runif(1) < min(1, target_diff)){
return (logV_prop)
}
}
return (logV_t)
return (MH_V(logV_, y_t, phi, psi, lamb))
}
# prior: phi ~ N(0, 1); psi ~ N(0, 1); sigma ~ IG(2.5, 0.025)
mu_phi <- 0; sig2_phi <- 1; mu_psi <- 0; sig2_psi <- 1; alpha_lamb <- 2.5; beta_lamb <- 0.025
T <- length(y)
set.seed(seed)
phi <- rnorm(1, mean=mu_phi, sd=sqrt(sig2_phi))
psi <- rnorm(1, mean=mu_psi, sd=sqrt(sig2_psi))
lamb <- rinvgamma(1, shape=alpha_lamb, rate=beta_lamb)
#phi <- 0.6 ; psi <- -0.4; lamb <- 0.2
logV_hist <- matrix(0, nrow=num_it, ncol=T+1)
phi_hist <- array(phi, dim=num_it)
psi_hist <- array(psi, dim=num_it)
lamb_hist <- array(lamb, dim=num_it)
for (t in 2:T+1){
logV_hist[1,t] <- phi + psi * logV_hist[1,t-1] + sqrt(lamb) * rnorm(1, 0, 1)
}
for (i in 2:num_it){
# MH sampling for ln V
logV <- c(logV_hist[i-1,], 0)
for (t in 1:T){
# logV starts from 0; y starts from 1
# a little bug for t = 0 and t = T + 1, but run it first
logV[t+1] <- MH_V(logV[c(t, t+1, t+2)], y[t], phi, psi, lamb)
}
logV <- logV[-(T+2)]
# Gibbs sampling for parameters
mu_phi <- (sig2_phi*sum(logV[-1]-psi*logV[-(T+1)]) + lamb*mu_phi)/(T*sig2_phi + lamb)
sig2_phi <- lamb*sig2_phi/(T*sig2_phi + lamb)
phi <- rnorm(1, mean=mu_phi, sd=sqrt(sig2_phi))
mu_psi <- (sig2_psi*sum(logV[-(T+1)]*(logV[-1]-phi)) + lamb*mu_psi) / (sig2_psi*sum(logV[-(T+1)]^2) + lamb)
sig2_psi <- lamb*sig2_psi/(sig2_psi*sum(logV[-(T+1)]^2) + lamb)
psi <- rnorm(1, mean=mu_psi, sd=sqrt(sig2_psi))
alpha_lamb <- alpha_lamb + T/2
beta_lamb <- 1/2*sum((logV[-1] - phi - psi*logV[-(T+1)])^2) + beta_lamb
lamb <- rinvgamma(1, shape=alpha_lamb, rate=beta_lamb)
print(paste(phi, psi, lamb, i))
logV_hist[i,] <- logV
phi_hist[i] <- phi
psi_hist[i] <- psi
lamb_hist[i] <- lamb
}
set.seed(4002)
# logV starts from 0; y starts from 1
y <- array(0, 1000)
ln_v <- array(0, 1001)
for (i in 2:1001){
ln_v[i] <- 0.5 - 0.332 * ln_v[i-1] + 0.12 * rnorm(1, 0, 1)
y[i-1] <- sqrt(exp(ln_v[i])) * rnorm(1, 0, 1)
}
library(invgamma)
seed=4002; num_it=1e5
#MCMC_SV <- function(y, num_it=1e5, seed=4002){
MH_V <- function(logV_, y_t, phi, psi, lamb){
logV_old <- logV_[1]; logV_t <- logV_[2]; logV_new <- logV_[3]
mu_t <- (phi*(1-psi) + psi*(logV_new + logV_old)) / (1 + psi^2)
tilde_mu_t <- mu_t + lamb/2 * (y_t^2 * exp(-mu_t) - 1)
tilde_lambda <- lamb / (1 + psi^2)
logV_prop <- rnorm(1, tilde_mu_t, sqrt(tilde_lambda))
nominator <- exp(-y_t^2/2 * exp(-logV_prop))
denominator <- exp(-y_t^2/2 * exp(-mu_t) * (1 + mu_t - logV_prop))
target_diff <- nominator / denominator
if (!is.na(target_diff)){
if (runif(1) < min(1, target_diff)){
return (logV_prop)
}
}
#return (logV_t)
return (MH_V(logV_, y_t, phi, psi, lamb))
}
# prior: phi ~ N(0, 1); psi ~ N(0, 1); sigma ~ IG(2.5, 0.025)
mu_phi <- 0; sig2_phi <- 1; mu_psi <- 0; sig2_psi <- 1; alpha_lamb <- 2.5; beta_lamb <- 0.025
T <- length(y)
set.seed(seed)
phi <- rnorm(1, mean=mu_phi, sd=sqrt(sig2_phi))
psi <- rnorm(1, mean=mu_psi, sd=sqrt(sig2_psi))
lamb <- rinvgamma(1, shape=alpha_lamb, rate=beta_lamb)
#phi <- 0.6 ; psi <- -0.4; lamb <- 0.2
logV_hist <- matrix(0, nrow=num_it, ncol=T+1)
phi_hist <- array(phi, dim=num_it)
psi_hist <- array(psi, dim=num_it)
lamb_hist <- array(lamb, dim=num_it)
for (t in 2:T+1){
logV_hist[1,t] <- phi + psi * logV_hist[1,t-1] + sqrt(lamb) * rnorm(1, 0, 1)
}
for (i in 2:num_it){
# MH sampling for ln V
logV <- c(logV_hist[i-1,], 0)
for (t in 1:T){
# logV starts from 0; y starts from 1
# a little bug for t = 0 and t = T + 1, but run it first
logV[t+1] <- MH_V(logV[c(t, t+1, t+2)], y[t], phi, psi, lamb)
}
logV <- logV[-(T+2)]
# Gibbs sampling for parameters
mu_phi <- (sig2_phi*sum(logV[-1]-psi*logV[-(T+1)]) + lamb*mu_phi)/(T*sig2_phi + lamb)
sig2_phi <- lamb*sig2_phi/(T*sig2_phi + lamb)
phi <- rnorm(1, mean=mu_phi, sd=sqrt(sig2_phi))
mu_psi <- (sig2_psi*sum(logV[-(T+1)]*(logV[-1]-phi)) + lamb*mu_psi) / (sig2_psi*sum(logV[-(T+1)]^2) + lamb)
sig2_psi <- lamb*sig2_psi/(sig2_psi*sum(logV[-(T+1)]^2) + lamb)
psi <- rnorm(1, mean=mu_psi, sd=sqrt(sig2_psi))
alpha_lamb <- alpha_lamb + T/2
beta_lamb <- 1/2*sum((logV[-1] - phi - psi*logV[-(T+1)])^2) + beta_lamb
lamb <- rinvgamma(1, shape=alpha_lamb, rate=beta_lamb)
print(paste(phi, psi, lamb, i))
logV_hist[i,] <- logV
phi_hist[i] <- phi
psi_hist[i] <- psi
lamb_hist[i] <- lamb
}
#}
